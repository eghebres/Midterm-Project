{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6201ea6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b737436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any numbers: nwspol, netustm, yrbrn\n",
    "# 6666 not applicable\n",
    "# 7777 refusal\n",
    "# 8888 don't know \n",
    "# 9999 no answer\n",
    "\n",
    "\n",
    "# 0 - 40 years: eduyrs\n",
    "# 66\n",
    "# 77\n",
    "# 88\n",
    "# 99\n",
    "\n",
    "\n",
    "# 0 - 10 (0 = fully reject, 10 = fully agree) \n",
    "# ppltrst, trstprl, trstlgl, trstplt, trstprt, trstep, trstun, stfeco, stfedu,euftf,atchctr\n",
    "# \n",
    "# 66\n",
    "# 77\n",
    "# 88\n",
    "# 99\n",
    "\n",
    "# 1 - 4 (1 = very interested, 4 = not interested)\n",
    "# polintr, \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1 - 5 (1 = not at all, 5 = a great deal)\n",
    "# psppsgva, actorlga, cptppola, \n",
    "\n",
    "\n",
    "# 1 Male, 2 Female, 9 No answer: gndr, vote\n",
    "# 3 not eligible, 7 refusal, 8 don't know\n",
    "\n",
    "# 1 Yes 2 No \n",
    "# uemp12m, brncntr, ctzcntr, dscrgrp, facntr, mocntr\n",
    "# 7 refusal, 8 don't know, 9 no answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e976f84",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd1b7c0",
   "metadata": {},
   "source": [
    " ## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1225136",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ESS = pd.read_csv('ESS8e02_2.csv')\n",
    "ESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f219d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "ESS.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faf616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columns do I want to keep?\n",
    "\n",
    "# nwspol       minutes spent watching/reading news about politics and current affairs\n",
    "# netustm      internet use, how much time on typical day, in minutes\n",
    "# ppltrst      most people can be trusted or you can't be too careful\n",
    "# gndr         gender (1 Male - 2 Female) \n",
    "# yrbrn        year of birth\n",
    "# intewde      place of interview: (1 East) or (2 West) Germany\n",
    "# polintr      how interested in politics\n",
    "# psppsgva     political system allows people to have a say in what the government does\n",
    "# pspippla     \n",
    "# cptppola     confident in own ability to participate in politics\n",
    "# actrolga     able to take active role in political group\n",
    "# trstprl      trust in country's parliament\n",
    "# trstlgl      trust in the legal system\n",
    "# trstplt      trust in politicians\n",
    "# trstprt      trust in political parties\n",
    "# trstep       trust in the European Parliament\n",
    "# trstun       trust in the United Nations\n",
    "# vote         voted in last election\n",
    "# stfeco       how satisfied with present state of economy\n",
    "# stfedu       state of education in country nowadays\n",
    "# euftf        European unification should go further or has gone too far\n",
    "# atchctr      how emotionally attached are you to your country\n",
    "# dscrgrp      member of a group that is discriminated against in the country\n",
    "# happy        how happy are you\n",
    "# brncntr      born in country\n",
    "# facntr       father born in country\n",
    "# mocntr       mother born in country\n",
    "# ctzcntr      citizen of country \n",
    "# eduyrs       years of full-time education completed\n",
    "# uemp12m      any period of unemployment that lasted longer than 12 months\n",
    "# edubde1      highest level of education successfully completed (school) -> Germany\n",
    "# eduade2      highest level of education successfully completed (university etc) -> Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b036020b",
   "metadata": {},
   "source": [
    "## Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ab9c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ESS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855acc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a57d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ESS.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a791fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ESS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec9a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns and put in lower case\n",
    "# not necessary since the column names are already in lower case\n",
    "\n",
    "# cols = []\n",
    "# for colname in ESS.columns:\n",
    "#     cols.append(colname.lower())\n",
    "# ESS.columns = cols\n",
    "\n",
    "# more renaming done in Notebook 1.04 (examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d653e73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ESS.dtypes\n",
    "ESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc643b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ESS.isna().sum()\n",
    "\n",
    "# ESS.isna() will only show False/True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d41f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7948e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tricky here:\n",
    "\n",
    "# dataset barely has NaNs\n",
    "# but answers like 'I dont know', 'No answer' is encoded as: \n",
    "# 6/66/666/6666  7/77/777/7777  8/88/888/8888\n",
    "# different depending on column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd66e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what to do with these 'empty' values\n",
    "\n",
    "# look at how large fraction of these values is \n",
    "# fill in the mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb7572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns before cleaning! Since there are too many to be cleaned otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9991c4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79b72c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# not done yet, insert more columns\n",
    "\n",
    "data = ESS[['nwspol', 'netustm', 'ppltrst', 'gndr', 'yrbrn', 'agea', 'intewde', 'polintr', 'psppsgva', 'cptppola', 'actrolga', 'trstprl', 'trstlgl', 'trstplt', 'trstprt', 'trstep', 'trstun', 'vote', 'stfeco', 'stfedu', 'euftf', 'atchctr', 'atcherp', 'dscrgrp', 'happy', 'brncntr', 'facntr', 'mocntr', 'ctzcntr', 'eduyrs', 'uemp12m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d20e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf6f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c2bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818fa0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose only features that don't need to be recoded later (no nominal with >2 choices)\n",
    "# Take features which would be used in draft model and categorize based on what miss dict to apply.\n",
    "\n",
    "\n",
    "# 7, 8, 9 are missings \n",
    "features1 = ['polintr', 'psppsgva', 'actrolga', 'cptppola', 'vote', 'dscrgrp',\n",
    "            'ctzcntr', 'brncntr', 'facntr', 'mocntr']\n",
    "\n",
    "\n",
    "# 6, 7, 8, 9 are missings\n",
    "features2 = ['gndr', 'uemp12m']\n",
    "\n",
    "# 77, 88, 99 are missing\n",
    "features3 = ['ppltrst', 'trstprl', 'trstlgl', 'trstplt', 'trstprt', 'trstep', 'trstun', 'stfeco', 'stfedu', 'euftf', 'happy', 'atchctr', 'atcherp',\n",
    "             'eduyrs']\n",
    "\n",
    "# 666, 777, 888, 999 are missings\n",
    "features4 = ['agea']\n",
    "\n",
    "# 7777, 8888, 9999 are missings\n",
    "features5 = ['nwspol', 'yrbrn']\n",
    "\n",
    "# 6666, 7777, 8888, 9999 are missings\n",
    "features6 = ['netustm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8436fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = features1 + features2 + features3 + features4 + features5 + features6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433cd842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Overall number of variables:\", len(all_vars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afbc706",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables = all_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dff5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries based on which the features numerical missings would be recoded to NaN\n",
    "# One dictionary for each feature list (except features0 that don't contain any missings)\n",
    "\n",
    "# Universal missing value\n",
    "missing = pd.np.nan\n",
    "\n",
    "# Dictionaries mapping numerics to missing var based on how features to recode were implemented. I check labels in SPSS.\n",
    "missRecDict1 = {7: missing, 8: missing, 9: missing}\n",
    "missRecDict2 = {6: missing, 7: missing, 8: missing, 9: missing}\n",
    "missRecDict3 = {77: missing, 88: missing, 99: missing}\n",
    "missRecDict4 = {666: missing, 777: missing, 888: missing, 999: missing}\n",
    "missRecDict5 = {7777: missing, 8888: missing, 9999: missing}\n",
    "missRecDict6 = {6666: missing, 7777: missing, 8888: missing, 9999: missing}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2a74ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d99dec6",
   "metadata": {},
   "source": [
    "### Recoding missing from numericals into NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e663273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Data_m, where 'm' stands for \"missings\".\n",
    "\n",
    "Data_m = pd.DataFrame()\n",
    "Data_m[features1] = data[features1].replace(missRecDict1)\n",
    "Data_m[features2] = data[features2].replace(missRecDict2)\n",
    "Data_m[features3] = data[features3].replace(missRecDict3)\n",
    "Data_m[features4] = data[features4].replace(missRecDict4)\n",
    "Data_m[features5] = data[features5].replace(missRecDict5)\n",
    "Data_m[features6] = data[features6].replace(missRecDict6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce8f27f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c732a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the variables that are not country specific, ordinal, and not part of the admistrative group\n",
    "ordinal = all_variables.query(\"Country_specific == \\\"no\\\" & Scale_type == \\\"ordinal\\\" and Group != \\\"Group Administrative variables\\\"\")\n",
    "\n",
    "# get the continous variables mentioned above \n",
    "continious = all_variables.query( \"Name in [\\\"agea\\\",\\\"eduyrs\\\",\\\"nwspol\\\",\\\"netustm\\\"]\")\n",
    "\n",
    "# get the nominal variables mentioned above \n",
    "nominal = all_variables.query( \"Name in [\\\"cntry\\\",\\\"gndr\\\"]\")\n",
    "\n",
    "# append them to one data frame\n",
    "variables = pd.concat([nominal,continious,ordinal]).reset_index(drop=True)\n",
    "variables.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59873751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac49fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6abfa4",
   "metadata": {},
   "source": [
    "#### Save data with selected features and correctly encoded missings as Data_missings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a48e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_m.to_csv('Data_missings.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cffd11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4680115",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d3052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columns are numericals?\n",
    "# Most must be categoricals\n",
    "# How do I want to work with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a16a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean of different columns\n",
    "#### EXAMPLE ######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns above threshold\n",
    "# Lab 7.01 and 7.02 answers Drive Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f1261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "plt.scatter(eduyrs, trstprl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## PUT IN BEGINNING CELL ##########################\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a45f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Barplots\n",
    "sns.barplot(x=\"intewde\", y=\"polintr\", data=data)\n",
    "plt.show()\n",
    "\n",
    "# 1 = East Germany\n",
    "# 2 = West Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62c8b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"intewde\", y=\"trstprl\", data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"intewde\", y=\"trstep\", data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f7410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"intewde\", y=\"dscrgrp\", data=data)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9539b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d22b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32f5ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots\n",
    "sns.boxplot(x = 'eduyrs',y='trstlgl', data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f9b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots\n",
    "sns.displot(data['eduyrs'], bins=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2452ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatterplots are great to compare two distinct variables and see if they are somehow related!\n",
    "sns.scatterplot(x=data['trstprt'], y=data['eduyrs'])\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0, 60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73708220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the big bomb of Visual Data Anlysis\n",
    "sns.pairplot(data)\n",
    "plt.show()\n",
    "\n",
    "## replace the false values with mean!!\n",
    "# https://stackoverflow.com/questions/48144828/how-to-replace-certain-values-in-a-pandas-column-with-the-mean-column-value-of-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33788894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any revelations through Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20f962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation: Is our datacorrelations_matrix = data.corr()\n",
    "correlations_matrix = data.corr()\n",
    "correlations_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881a7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "sns.heatmap(correlations_matrix, annot=True)\n",
    "plt.show()\n",
    "\n",
    "# looks crazy! replacement will probably change the look of the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69775e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "\n",
    "# EVERYTHING CORRECT SO FAR? \n",
    "# HOW TO ANALYSE DATASET WITH ONLY CATEGORICALS? DIFFERENCE TO NUMERICALS?\n",
    "# DISTRIBUTION AND EVERYTHING (PLOTS, ETC)\n",
    "\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1edf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef45bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de14a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### #### LINEAR REGRESSION MODEL #### ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43cf809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX LINEAR REGRESSION RE-DO COMPLETELY AFTER BOOTCAMP\n",
    "# FOCUS ON PROPERLY ENCODING THE VARIABLES! DIFFICULT TO SEPERATE THE DIFFERENT VALUES AND MEANINGS OF VALUES\n",
    "# FIND SMART SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e5a80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ef0db63",
   "metadata": {},
   "source": [
    "## X/y Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9525fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do X-y Split on dataset\n",
    "y = data['TARGET_D']\n",
    "X = data.drop(['TARGET_D'], axis=1)\n",
    "\n",
    "# already encoded dataset\n",
    "# TARGET (y) is the trust variable (choose different ones: trstprl, trstprt, trstep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed5e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d0bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical and numerical features are going to be treated differently\n",
    "\n",
    "X_num = X.select_dtypes(include = np.number)\n",
    "X_cat = X.select_dtypes(include = object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06c25ae",
   "metadata": {},
   "source": [
    "## Normalizing numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400b441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing and Standardizing data - only for numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca68013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need scaling: in order to find out wheter we have to scale or not we look at the ranges\n",
    "# range between min and max\n",
    "# if the range is very big(in this example AVGGIFT after squaring in the 180000 and IC5 at 18 ~ unresonable)\n",
    "X_num.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d195a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after MinMaxScaler you have to put X-normalized back into DataFrame, so that we can see the columns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "MinMaxtransformer = MinMaxScaler().fit(X_num)\n",
    "X_normalized = MinMaxtransformer.transform(X_num)\n",
    "\n",
    "print(X_normalized.shape)\n",
    "X_normalized = pd.DataFrame(X_normalized,columns=X_num.columns)\n",
    "X_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3848374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "Standardtransformer = StandardScaler().fit(X_num)\n",
    "X_standardized = Standardtransformer.transform(X_num)\n",
    "print(X_standardized.shape)\n",
    "X_standardized = pd.DataFrame(X_standardized,columns=X_num.columns)\n",
    "X_standardized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02213df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standardized.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caebf908",
   "metadata": {},
   "source": [
    "## Normalizing categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3aecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ ENCODE CERTAIN CATEGORICAL COLUMNS DIFFERENTLY? #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b083529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding is a way to turn categorical variables into multiple numerical columns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder().fit(X_cat)\n",
    "#endoder # ONeHotEncoder(drop='first').fit(X_cat)\n",
    "print(encoder.categories_)\n",
    "encoded = encoder.transform(X_cat).toarray()\n",
    "print(encoded)\n",
    "onehot_encoded = pd.DataFrame(encoded,columns=encoder.categories_)\n",
    "onehot_encoded = pd.DataFrame(encoded,columns=['Female','Male','U'])\n",
    "#onehot_encoded = pd.DataFrame(encoded,columns=[Male','U'])\n",
    "onehot_encoded.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb90c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all the information into a single dataset with all features\n",
    "X = pd.concat([X_normalized, onehot_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['TARGET_D']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61311a34",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba5fb78",
   "metadata": {},
   "source": [
    "## Train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2991ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split is the way ML generates its claim to fame: \n",
    "# we build the model on a portion of the data but we then validate it in \n",
    "# another \"fresh\" portion\n",
    "# our model has no opportunity to \"cheat\": it must accurately guess the values \n",
    "# in the \"fresh\" dataset that it never saw before\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#random=initial set of training is always different, that way I will always get the same rows and not different rows\n",
    "#42 is a choice, its not given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6387de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc18c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08153a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we train/fit our model like yesterday\n",
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b966f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "predictions = lm.predict(X_train)\n",
    "r2_score(y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b897cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990081ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But now we evaluate it in the TEST portion of the data, that we did not use for training.\n",
    "# This way we know our model is genuinely guessing our donations, not just repeating the values it has seen in the training data\n",
    "\n",
    "\n",
    "r2_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606d9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f8a53",
   "metadata": {},
   "source": [
    "# Model Validation - Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d63b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "# r2 score\n",
    "predictions_test = lm.predict(X_test)\n",
    "print(\"r2 Score of test Data: \",round(r2_score(y_test, predictions_test),3))\n",
    "predictions_train = lm.predict(X_train)\n",
    "print(\"r2 Score of train Data: \",round(r2_score(y_train, predictions_train),3), \"\\n\")\n",
    "\n",
    "# mse\n",
    "y_pred = lm.predict(fifa_whole)\n",
    "print(\"mean squared error: \",round(mean_squared_error(y_pred,y),3))\n",
    "\n",
    "# rmse\n",
    "print(\"rooted mean squared error: \", round(np.sqrt(mean_squared_error(y_pred,y)),3),\"\\n\")\n",
    "\n",
    "# mae\n",
    "mae_test = mean_absolute_error(y_test, predictions_test)\n",
    "print(\"mean absolute error of test data:\",round(mae_test,3))\n",
    "mae_train = mean_absolute_error(y_train, predictions_train)\n",
    "print(\"mean absolute error of train data:\", round(mae_train,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b79c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=mean_squared_error(y_test,predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14459c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c7278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we make the same separation into numerical and categorical\n",
    "X_for_p_num = data_for_p.select_dtypes(include = np.number)\n",
    "X_for_p_cat = data_for_p.select_dtypes(include = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bed9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for normalization and one hot encoding we need to make sure we remain consisten with the training data:\n",
    "# If we MinMax scale just this piece of data, a \"1\" in this dataset means something very different from a 1 in the original dataset\n",
    "# If we one-hot-encode in this dataset, the order of the columns (Unknown, Male, Female) may turn out different\n",
    "#to avoid this, we use the same transformers we had already defined before, we do not fit them again.\n",
    "encoded_for_p = encoder.transform(X_for_p_cat).toarray()\n",
    "encoded_for_p\n",
    "encoder.categories_\n",
    "onehot_encoded_for_p = pd.DataFrame(encoded_for_p,columns=encoder.categories_)\n",
    "#onehot_encoded_for_p = onehot_encoded_for_p.drop(['Female'],axis=1)\n",
    "onehot_encoded_for_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e65023",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_p_normalized = MinMaxtransformer.transform(X_for_p_num)\n",
    "X_for_p_normalized = pd.DataFrame(X_for_p_normalized,columns=X_for_p_num.columns)\n",
    "\n",
    "#merge back all of our labels\n",
    "X_for_p = pd.concat([X_for_p_normalized, onehot_encoded_for_p], axis=1)\n",
    "\n",
    "X_for_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ab250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict and inspect results\n",
    "results_for_p = lm.predict(X_for_p)\n",
    "\n",
    "pd.concat([data_for_p,pd.Series(results_for_p, name='estimate')],axis=1).head()\n",
    "#estimate is the result we get from p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(mae)\n",
    "#if there is a minus before, you'll get rid of it by taking the absolute number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = math.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37f546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, predictions)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0720b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## LINEAR REGRESSION DONE? ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca482d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ RESULTS? WHAT INDICATIONS? HOW TO INTERPRET RESULTS? ####################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6007862a",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dfb0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# p-value of 5%\n",
    "pval = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0fe0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 4.4 for Help\n",
    "# Hypothesis:\n",
    "# HO:\n",
    "# H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5b72e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two tailed test\n",
    "# one tailed test\n",
    "# crosstab function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b46a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the crosstab function, find the department that has the most hourly workers.\n",
    "# department = pd.crosstab(salaries_df['Department'],salaries_df['Salary or Hourly']).sort_values(by='Hourly',ascending=False).reset_index()\n",
    "# department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e2f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a73c5b5c",
   "metadata": {},
   "source": [
    "# Construction Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e0fdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d9d6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d223a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c303c01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902093f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4ffabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4944ffc6",
   "metadata": {},
   "source": [
    "## Hypothesis Tests for Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d22263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add88b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb538be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb42d3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae40888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa388a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7560db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178766b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### WHAT DO WE LEARN FROM MY ANALYSIS ########\n",
    "######## GIVES REASON FOR FURTHER RESEARCH? #########\n",
    "####### RELEVANT INFORMATION ##########\n",
    "####### ANYTHING SURPRISING? DID IT CONFIRM MY ASSUMPtIONS #######\n",
    "###### PUT ASSUMPTIONS IN THE INTRO #  AND HYPOTHESIS TESTING ###########"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
